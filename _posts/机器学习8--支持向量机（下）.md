title: 机器学习8--支持向量机（下）
date: 2014-06-05 16:55:37
tags: ML
---
# 机器学习8--支持向量机（下）

> **上节回顾：**从逻辑回归引出支持向量机-->定义函数间隔和几何间隔-->最优间隔分类器（通过最大化间隔，得到最优）-->引出拉格朗日对偶（作用：通过对偶将算法变得更高效；处理高维）-->将对偶用到最优间隔分类器
**本节内容：**核函数（升维）-->判定是否是有效的核函数-->L1 norm 软间隔SVM（针对不可分的情况）-->**第三种求解最优化的方法：坐标上升法**-->SMO优化算法（最快的二次规划优化算法）

## 核函数
1、定义
> ![](/img/1401589792400.png)

2、核函数的作用
> a、低维映射到高维，从而更好的拟合；
b、将不可分的情况变为可分

3、举例：
> 例一：
![](/img/1401589996693.png)
![](/img/1401590011818.png)
说明：时间复杂度由![](/img/1401590126082.png)
例二：
高斯核（把原始特征映射到无穷维）：![](/img/1401590208271.png)
映射后的优点：
![](/img/1401590470703.png)

4、映射后怎样进行**预测**：
> 预测函数：![](/img/1401590532017.png)
映射后：将![](/img/1401590627850.png)
**问题：**怎样***求取***和判断核函数？下面将会介绍。

## 核函数的判定
1、符号说明
> K：核函数矩阵$K=\{K_{ij}\} $   第i,j个样本
$K_{ij}$ 或者$K(x^{(i)},x^{(j)}) $ ：核函数$K_{ij}=K(x^{(i)},x^{(j)}) $ 

2、利用**Mercer定理**
> ![](/img/1401590742752.png)
简而言之，**K是一个有效的核函数<-->核函数矩阵是对称半正定**

## L1 norm 软间隔SVM
当不可分时，利用**L1 软间隔**进行分离
1、 加入软间隔后的模型：
> **（1）凸规划**： 
![](/img/1401591458911.png)
其中，C是离群点的权重（我们预定的，为已知数），越大表明对目标函数影响越大，也就是月不希望看到离群点。引入非负参数![](/img/1401591999936.png)（称为松弛变量） ， 就允许某些样本点的函数间隔小于1，即在最大间隔区间里面，或者函数间隔是负数，即样本点在对方的区域中。
**（2）拉格朗日算子：**
![](/img/1401591501740.png)
其中，![](/img/1401591562176.png)
**（3）推导结果**
跟前面模型类似：先写出拉格朗日公式 （如上） ，然后将其看作是变量 w 和 b的函数，分别对其求偏导，得到 w 和 b 的表达式。然后代入公式中，求带入后公式的极大值。得到：
![](/img/1401592399557.png)
>> KTT条件：
![](/img/1401592240525.png)

## 第三种求解最优化的方法：坐标上升法
1、三种求解最优化的方法：
> **（1）梯度上升法**(求解最小值问题时，称作梯度下降法)
**（2）牛顿法**（求解最值）
**（3）坐标上升法**（求解最小值问题时，称作坐标下降法）

2、假设求解下面问题：
> ![](/img/1401592589750.png)
其中，![](/img/1401592830611.png)

3、算法过程：
> ![](/img/1401592929690.png)
>> ![](/img/1401593088183.png)
![](/img/1401593108069.png)

## SMO优化算法
最快的二次规划优化算法，特别针对线性 SVM 和数据稀疏时性能更优。
1、前面得到的结果
> 首先，先看前面的到的结果，如下图：
![](/img/1401592399557.png)
>> 这个问题中：
![](/img/1401593370616.png)
按照坐标上升法的思路，只固定一个![](/img/1401593529971.png)的话，由于限制条件中存在![](/img/1401593550357.png)，将导致![](/img/1401593529971.png)不再是变量。
因此，我们一次选取两个参数做优化。

**2、SMO的主要步骤**
> ![](/img/1401593654090.png)
注：第一步，利用启发式方法选取![](/img/1401593901295.png)。第二步，固定其他参数，![](/img/1401593977721.png)

**3、 具体步骤**
> （1）固定除![](/img/1401593749701.png)以外的参数，得：
![](/img/1401593773158.png)
（2）为了方便:
![](/img/1401593811665.png)
>> 如下图：
![](/img/1401594617028.png)
其中，满足：![](/img/1401594674995.png)和![](/img/1401594696380.png)
L和H的范围：
![](/img/1401595192630.png)

> （3）将![](/img/1401595320429.png)带入W中：
![](/img/1401595417198.png)
展开，得：
![](/img/1401595488545.png)
（4）这就是二次函数的最小值问题，容易求得（在纸上画图很容易看出来）：
![](/img/1401595811976.png)
其中，![](/img/1401595827675.png)为最终结果。![](/img/1401595900489.png)为求导得到的结果。
同理，求得![](/img/1401596593534.png)的最优解。

## 总结
1、本章的系统结构：
> 至此，我们得到：
预测问题只需要求解![](/img/1401596884593.png)，即：
![](/img/1401596939257.png)
<-->上面的过程（SMO）求得![](/img/1401596616059.png)为![](/img/1401596062693.png)的最优解
<-->![](/img/1401596318573.png)
<-->![](/img/1401596439772.png)
<-->![](/img/1401596460479.png)
<-->![](/img/1401596488661.png)
<-->![](/img/1401596500584.png)（最大化几何间隔问题）

2、关于核问题（升维）的说明
> 核问题用来替换第一步中的部分：
![](/img/1401597230916.png)
























